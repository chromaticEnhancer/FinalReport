@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{10.1007/978-3-030-72610-2_17,
  author    = {Golyadkin, Maksim
               and Makarov, Ilya},
  editor    = {van der Aalst, Wil M. P.
               and Batagelj, Vladimir
               and Ignatov, Dmitry I.
               and Khachay, Michael
               and Koltsova, Olessia
               and Kutuzov, Andrey
               and Kuznetsov, Sergei O.
               and Lomazova, Irina A.
               and Loukachevitch, Natalia
               and Napoli, Amedeo
               and Panchenko, Alexander
               and Pardalos, Panos M.
               and Pelillo, Marcello
               and Savchenko, Andrey V.
               and Tutubalina, Elena},
  title     = {Semi-automatic Manga Colorization Using Conditional Adversarial Networks},
  booktitle = {Analysis of Images, Social Networks and Texts},
  year      = {2021},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {230--242},
  abstract  = {Manga colorization is time-consuming and hard to automate. In this paper, we propose a conditional adversarial deep learning approach for semi-automatic manga images colorization. The system directly maps a tuple of grayscale manga page image and sparse color hint constructed by the user to an output colorization. High-quality colorization can be obtained in a fully automated way, and color hints allow users to revise the colorization of every panel independently. We collect a dataset of manually colorized and grayscale manga images for training and evaluation. To perform supervised learning, we construct synthesized monochrome images from colorized. Furthermore, we suggest a few steps to reduce the domain gap between synthetic and real data. Their influence is evaluated both quantitatively and qualitatively. Our method can achieve even better results by fine-tuning with a small number of grayscale manga images of a new style. The code is available at github.com.},
  isbn      = {978-3-030-72610-2}
}

@misc{isola2018imagetoimage,
  title         = {Image-to-Image Translation with Conditional Adversarial Networks},
  author        = {Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
  year          = {2018},
  eprint        = {1611.07004},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{hensman2017cganbased,
  title         = {cGAN-based Manga Colorization Using a Single Training Image},
  author        = {Paulina Hensman and Kiyoharu Aizawa},
  year          = {2017},
  eprint        = {1706.06918},
  archiveprefix = {arXiv},
  primaryclass  = {cs.GR}
}

@misc{furusawa2017comicolorization,
  title         = {Comicolorization: Semi-Automatic Manga Colorization},
  author        = {Chie Furusawa and Kazuyuki Hiroshiba and Keisuke Ogaki and Yuri Odagiri},
  year          = {2017},
  eprint        = {1706.06759},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{li-2017-deep,
  author  = {Chengze Li and Xueting Liu and Tien-Tsin Wong},
  title   = {Deep Extraction of Manga Structural Lines},
  journal = {ACM Transactions on Graphics (SIGGRAPH 2017 issue)},
  month   = {July},
  year    = {2017},
  volume  = {36},
  number  = {4},
  pages   = {117:1--117:12}
}

@misc{he2015deep,
  title         = {Deep Residual Learning for Image Recognition},
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year          = {2015},
  eprint        = {1512.03385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{ronneberger2015unet,
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  author        = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  year          = {2015},
  eprint        = {1505.04597},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{kim2022styleaware,
  title         = {A Style-aware Discriminator for Controllable Image Translation},
  author        = {Kunhee Kim and Sanghun Park and Eunyeong Jeon and Taehun Kim and Daijin Kim},
  year          = {2022},
  eprint        = {2203.15375},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{arjovsky2017wasserstein,
  title         = {Wasserstein GAN},
  author        = {Martin Arjovsky and Soumith Chintala and LÃ©on Bottou},
  year          = {2017},
  eprint        = {1701.07875},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@article{ACPR2017ZLM,
  author  = {LvMin Zhang, Yi Ji and ChunPing Liu},
  title   = {Style Transfer for Anime Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN},
  conference = {Asian Conference on Pattern Recognition (ACPR)},
  year    = {2017},
}

@article{varga2017convolutional,
  title={Convolutional Neural Networks for automatic image colorization},
  author={Varga, Domonkos Istv{\'a}n and Szir{\'a}nyi, Tam{\'a}s},
  year={2017},
  publisher={Neumann J{\'a}nos Sz{\'a}m{\'\i}t{\'o}g{\'e}p-tudom{\'a}nyi T{\'a}rsas{\'a}g (NJSZT)}
}

@misc{zhu2020unpaired,
      title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks}, 
      author={Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
      year={2020},
      eprint={1703.10593},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{zhang2019colorization,
  title={Colorization for anime sketches with cycle-consistent adversarial network},
  author={Zhang, Guanghua and Qu, Mengnan and Jin, Yuhao and Song, Qingpeng},
  journal={International Journal of Performability Engineering},
  volume={15},
  number={3},
  pages={910},
  year={2019}
}

@article{qu2006manga,
  title={Manga colorization},
  author={Qu, Yingge and Wong, Tien-Tsin and Heng, Pheng-Ann},
  journal={ACM Transactions on Graphics (ToG)},
  volume={25},
  number={3},
  pages={1214--1220},
  year={2006},
  publisher={ACM New York, NY, USA}
}

@article{jiramahapokee2023inkn,
  title={inkn'hue: Enhancing Manga Colorization from Multiple Priors with Alignment Multi-Encoder VAE},
  author={Jiramahapokee, Tawin},
  journal={arXiv preprint arXiv:2311.01804},
  year={2023}
}

@article{li2017deep,
  title={Deep extraction of manga structural lines},
  author={Li, Chengze and Liu, Xueting and Wong, Tien-Tsin},
  journal={ACM Transactions on Graphics (TOG)},
  volume={36},
  number={4},
  pages={1--12},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{huang2021fully,
  title={A fully-automatic image colorization scheme using improved CycleGAN with skip connections},
  author={Huang, Shanshan and Jin, Xin and Jiang, Qian and Li, Jie and Lee, Shin-Jye and Wang, Puming and Yao, Shaowen},
  journal={Multimedia Tools and Applications},
  volume={80},
  number={17},
  pages={26465--26492},
  year={2021},
  publisher={Springer}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}

@misc{park2020contrastive,
      title={Contrastive Learning for Unpaired Image-to-Image Translation}, 
      author={Taesung Park and Alexei A. Efros and Richard Zhang and Jun-Yan Zhu},
      year={2020},
      eprint={2007.15651},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{shimizu2021painting,
  title={Painting Style-Aware Manga Colorization Based on Generative Adversarial Networks},
  author={Shimizu, Yugo and Furuta, Ryosuke and Ouyang, Delong and Taniguchi, Yukinobu and Hinami, Ryota and Ishiwatari, Shonosuke},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
  pages={1739--1743},
  year={2021},
  organization={IEEE}
}
